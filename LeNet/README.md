# LeNet 卷积神经网络实现

本项目实现了经典的LeNet-5卷积神经网络架构。LeNet-5是由Yann LeCun等人在1998年提出的用于手写数字识别的卷积神经网络。

## 网络架构

LeNet-5是一个经典的卷积神经网络，专为MNIST手写数字识别任务设计。网络架构如下：

### 详细架构说明

| 层 | 类型 | 参数 | 输入形状 | 输出形状 | 说明 |
|---|---|---|---|---|---|
| 输入 | - | - | 1×28×28 | 1×28×28 | MNIST灰度图像 |
| C1 | 卷积层 | 6个5×5卷积核，padding=2 | 1×28×28 | 6×28×28 | 提取6个特征图 |
| S2 | 最大池化 | 2×2池化，stride=2 | 6×28×28 | 6×14×14 | 降采样，减少计算量 |
| C3 | 卷积层 | 16个5×5卷积核，padding=0 | 6×14×14 | 16×10×10 | 提取16个特征图 |
| S4 | 最大池化 | 2×2池化，stride=2 | 16×10×10 | 16×5×5 | 进一步降采样 |
| 展平 | Flatten | - | 16×5×5 | 400 | 将特征图展平 |
| F5 | 全连接层 | 400→84 | 400 | 84 | 第一个全连接层 |
| Dropout | Dropout | p=0.5 | 84 | 84 | 防止过拟合 |
| F6 | 全连接层 | 84→10 | 84 | 10 | 输出层，对应10个数字类别 |

### 网络特点

- **卷积层**：使用5×5卷积核提取特征
- **池化层**：使用2×2最大池化进行降采样
- **全连接层**：将特征映射到分类空间
- **Dropout**：防止过拟合，提高泛化能力
- **激活函数**：使用ReLU激活函数（PyTorch默认）

### 参数统计

- 总参数数量：约60K参数
- 卷积层参数：主要参数集中在全连接层
- 模型大小：轻量级，适合快速训练和推理

## 项目结构

```
LeNet/
├── data/                   # 数据集
│   └── MNIST               #MNIST数据集（下载后生成）
├── dataloader/             # 数据加载器
│   ├── __init__.py
│   └── mnist_loader.py     # MNIST数据集加载器
├── model/                  # 模型相关代码
│   └── lenet.py           # LeNet模型定义
├── utils/                  # 工具函数
│   └── visualization.py    # 可视化工具
├── train.py               # 训练脚本
└── evaluate.py            # 评估脚本
```

## 环境要求
- Python 3.12+
- PyTorch
- torchvision
- numpy
- matplotlib
- tqdm

## 使用说明
1. 运行训练：`python train.py`
2. 评估模型：`python evaluate.py`

## 训练参数
- 训练轮数：10 epochs
- 批次大小：64
- 学习率：0.001
- 优化器：Adam
- 学习率调度：StepLR (每5轮衰减0.9)
